{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d807abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x4, 5frames, pathces, Segformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c9e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import os, random, gc\n",
    "import numpy as np\n",
    "from src.fastai_fix import *\n",
    "from src.lovasz import lovasz_sym\n",
    "from src.ema import *\n",
    "import tifffile\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "from src.segformer import SegFormer\n",
    "from src.lovasz import lovasz_hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005addb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    path = 'data/'\n",
    "    out = 'experiments/init'\n",
    "    \n",
    "    num_workers = 12\n",
    "    seed = 2023\n",
    "    bs = 12#2\n",
    "    \n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    #torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CONFIG.seed)\n",
    "os.makedirs(CONFIG.out, exist_ok=True)\n",
    "\n",
    "def WrapperAdamW(param_groups,**kwargs):\n",
    "    return OptimWrapper(param_groups,torch.optim.AdamW)\n",
    "\n",
    "from src.radam import Over9000\n",
    "def WrapperOver9000(param_groups,**kwargs):\n",
    "    #param_groups = [{'params':p} for p in param_groups]\n",
    "    #return OptimWrapper(opt=Over9000(param_groups,**kwargs))\n",
    "    return OptimWrapper(param_groups,opt=Over9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a7338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2tensor(img,dtype:np.dtype=np.float32):\n",
    "    if img.ndim==2 : img = np.expand_dims(img,2)\n",
    "    img = np.transpose(img,(2,0,1))\n",
    "    return torch.from_numpy(img.astype(dtype, copy=False))\n",
    "\n",
    "def get_aug():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(),\n",
    "        A.VerticalFlip(),\n",
    "        A.RandomRotate90(),\n",
    "        #A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=30, p=0.9),\n",
    "        A.OneOf([\n",
    "            A.CropNonEmptyMaskIfExists(512//4,512//4,p=0.75),\n",
    "            A.RandomCrop(512//4,512//4,p=0.25),\n",
    "        ],p=1),\n",
    "        #OneOf([\n",
    "        #    OpticalDistortion(p=0.3),\n",
    "        #    GridDistortion(p=0.1),\n",
    "        #    PiecewiseAffine(p=0.3),\n",
    "        #], p=0.4),\n",
    "        #A.RandomBrightnessContrast(p=0.5)\n",
    "    ], p=1)\n",
    "\n",
    "class ContrailsDataset(Dataset):\n",
    "    def __init__(self, path, train=True, tfms=None, repeat=1):\n",
    "        self.path = os.path.join(path, 'train_adj2' if train else 'val_adj2')\n",
    "        self.fnames = sorted([fname for fname in os.listdir(self.path) if \\\n",
    "                       fname.split('.')[0].split('_')[-1] == 'img'])\n",
    "        self.train, self.tfms = train, tfms\n",
    "        self.nc = 3\n",
    "        self.repeat = repeat\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.repeat*len(self.fnames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx%len(self.fnames)\n",
    "        img = tifffile.imread(os.path.join(self.path, self.fnames[idx]))\n",
    "        img = img.reshape(*img.shape[:2],self.nc,-1)[:,:,:,0:5]\n",
    "        img = img.reshape(*img.shape[:2],-1)\n",
    "        mask = tifffile.imread(os.path.join(self.path, self.fnames[idx].replace('img','mask')))\n",
    "\n",
    "        if self.tfms is not None:\n",
    "            augmented = self.tfms(image=img,mask=mask)\n",
    "            img,mask = augmented['image'],augmented['mask']\n",
    "        \n",
    "        img = cv2.resize(img, (4*img.shape[1],4*img.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "        img,mask = img2tensor(img/255),img2tensor(mask/255)\n",
    "        img = img.view(self.nc, -1, *img.shape[1:])\n",
    "        \n",
    "        return img,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae1d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lovasz import lovasz_hinge\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target, reduction='mean'):\n",
    "        #n = input.shape[-1]\n",
    "        input = input.view(-1).float()\n",
    "        target = target.view(-1).float()\n",
    "        loss = -target*F.logsigmoid(input)*torch.exp(self.gamma*F.logsigmoid(-input)) -\\\n",
    "           (1.0 - target)*F.logsigmoid(-input)*torch.exp(self.gamma*F.logsigmoid(input))\n",
    "        loss = 100*loss\n",
    "        return loss.mean() if reduction=='mean' else loss\n",
    "    \n",
    "def loss_comb(x,y):\n",
    "    return FocalLoss(2)(x,y) + 0.7*lovasz_hinge(x,y,per_image=False)\n",
    "    \n",
    "class F_th(Metric):\n",
    "    def __init__(self, ths=np.arange(0.1,0.9,0.01), beta=1): \n",
    "        self.ths = ths\n",
    "        self.beta = beta\n",
    "        \n",
    "    def reset(self): \n",
    "        self.tp = torch.zeros(len(self.ths))\n",
    "        self.fp = torch.zeros(len(self.ths))\n",
    "        self.fn = torch.zeros(len(self.ths))\n",
    "        \n",
    "    def accumulate(self, learn):\n",
    "        pred,targ = flatten_check(torch.sigmoid(learn.pred.float()), \n",
    "                                  (learn.y > 0.5).float())\n",
    "        for i,th in enumerate(self.ths):\n",
    "            p = (pred > th).float()\n",
    "            self.tp[i] += (p*targ).float().sum().item()\n",
    "            self.fp[i] += (p*(1-targ)).float().sum().item()\n",
    "            self.fn[i] += ((1-p)*targ).float().sum().item()\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        self.dices = (1 + self.beta**2)*self.tp/\\\n",
    "            ((1 + self.beta**2)*self.tp + self.beta**2*self.fn + self.fp + 1e-6)\n",
    "        return self.dices.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f41d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.segformer import * \n",
    "\n",
    "class LSTM_block(nn.Module):\n",
    "    def __init__(self, n, **kwargs):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(n, n, batch_first=True, bidirectional=False, num_layers=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        s = x.shape\n",
    "        x = x.flatten(-2,-1).permute(0,3,1,2).flatten(0,1)\n",
    "        x = self.lstm(x)[0]\n",
    "        x = x.view(-1,s[3],s[4],s[1],s[2]).permute(0,3,4,1,2)\n",
    "        return x\n",
    "\n",
    "class SegFormer(nn.Module):\n",
    "    def __init__(self, arch='B0', pre=None, num_classes=1, ps=0.1, use_checkpoint=False, \n",
    "                 up_result=2, tta=1, **kwargs):\n",
    "        super().__init__()\n",
    "        if arch == 'B0':\n",
    "            self.backbone = mit_b0(use_checkpoint=use_checkpoint, **kwargs)\n",
    "            self.decode_head = SegFormerHead(feature_strides=[4, 8, 16, 32],\n",
    "                            in_channels=[32, 64, 160, 256],embedding_dim=256)\n",
    "        elif arch == 'B1':\n",
    "            self.backbone = mit_b1(use_checkpoint=use_checkpoint, **kwargs)\n",
    "            self.decode_head = SegFormerHead(feature_strides=[4, 8, 16, 32],\n",
    "                            in_channels=[64, 128, 320, 512],embedding_dim=256)\n",
    "        elif arch == 'B2':\n",
    "            self.backbone = mit_b2(use_checkpoint=use_checkpoint, **kwargs)\n",
    "            self.decode_head = SegFormerHead(feature_strides=[4, 8, 16, 32],\n",
    "                            in_channels=[64, 128, 320, 512],embedding_dim=768)\n",
    "        elif arch == 'B3':\n",
    "            self.backbone = mit_b3(use_checkpoint=use_checkpoint, **kwargs)\n",
    "            self.decode_head = SegFormerHead(feature_strides=[4, 8, 16, 32],\n",
    "                            in_channels=[64, 128, 320, 512],embedding_dim=768)\n",
    "        elif arch == 'B4':\n",
    "            self.backbone = mit_b4(use_checkpoint=use_checkpoint, **kwargs)\n",
    "            self.decode_head = SegFormerHead(feature_strides=[4, 8, 16, 32],\n",
    "                            in_channels=[64, 128, 320, 512],embedding_dim=768)\n",
    "        elif arch == 'B5':\n",
    "            self.backbone = mit_b5(use_checkpoint=use_checkpoint, **kwargs)\n",
    "            self.decode_head = SegFormerHead(feature_strides=[4, 8, 16, 32],\n",
    "                            in_channels=[64, 128, 320, 512],embedding_dim=768)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        if pre is not None:\n",
    "            print(f'loading {pre}')\n",
    "            self.load_state_dict(torch.load(pre)['state_dict'],strict=False)\n",
    "        \n",
    "        self.lstm = nn.ModuleList([LSTM_block(512),LSTM_block(320)])\n",
    "        #self.final_conv = nn.Sequential(\n",
    "        #    PixelShuffle_ICNR(self.decode_head.embedding_dim,self.decode_head.embedding_dim//4),\n",
    "        #    nn.Dropout2d(ps), nn.Conv2d(self.decode_head.embedding_dim//4,num_classes, 3, padding=1))\n",
    "        self.final_conv = nn.Conv2d(self.decode_head.embedding_dim,num_classes, 3, padding=1)\n",
    "        self.up_result,self.tta = up_result,tta\n",
    "        \n",
    "    def pred(self, x):\n",
    "        nt = x.shape[2]\n",
    "        x = x.permute(0,2,1,3,4).flatten(0,1)\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        x = [x[0].view(-1,nt,*x[0].shape[1:])[:,-1], x[1].view(-1,nt,*x[1].shape[1:])[:,-1], \n",
    "             self.lstm[1](x[2].view(-1,nt,*x[2].shape[1:]))[:,-1],\n",
    "             self.lstm[0](x[3].view(-1,nt,*x[3].shape[1:]))[:,-1]]\n",
    "        x = self.decode_head(x)\n",
    "        \n",
    "        if self.up_result != 0: x = F.interpolate(self.final_conv(x),\n",
    "                            scale_factor=self.up_result,mode='bilinear',align_corners=False)\n",
    "        return x\n",
    "    \n",
    "    def forward(self,x):\n",
    "        if self.training: return self.pred(x)\n",
    "        else: return torch.stack([TTAi(self.pred(TTA(x,i)),i) \n",
    "                                  for i in range(self.tta)], 0).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c01931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = 'experiments'\n",
    "fname = 'init20'\n",
    "\n",
    "for fold in range(1):\n",
    "    ds_train = ContrailsDataset(CONFIG.path, train=True, tfms=get_aug(), repeat=4)\n",
    "    ds_val = ContrailsDataset(CONFIG.path, train=False, tfms=None)\n",
    "    dl_train = DataLoader(ds_train, CONFIG.bs, num_workers=CONFIG.num_workers, shuffle=True, drop_last=True)\n",
    "    dl_val = DataLoader(ds_val, 4, num_workers=CONFIG.num_workers, shuffle=False, drop_last=False)\n",
    "    \n",
    "    model = SegFormer(arch='B2', pre='segformer.b2.512x512.ade.160k.pth', num_classes=1, \n",
    "                      ps=0,up_result=1,tta=4).cuda()\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "    data = DataLoaders(dl_train,dl_val).cuda()\n",
    "\n",
    "    learn = Learner(data, \n",
    "                    model,\n",
    "                    path = CONFIG.out, \n",
    "                    loss_func=loss_comb,\n",
    "                    metrics=[F_th()],\n",
    "                    cbs=[\n",
    "                    GradientClip(3.0),\n",
    "                    GradientAccumulation(32//CONFIG.bs),\n",
    "                    CSVLogger(),\n",
    "                    #SaveModelCallback(monitor='f_th'),\n",
    "                    ],\n",
    "                    opt_func=partial(WrapperOver9000,eps=1e-4),\n",
    "                    #splitter = SwinFormer.split_layers\n",
    "                   ).to_fp16()\n",
    "    \n",
    "    learn.fit_one_cycle(36, lr_max=3.5e-4, pct_start=0.1)\n",
    "    torch.save(learn.model.module.state_dict(),os.path.join(OUT,f'{fname}_{fold}.pth'))\n",
    "    \n",
    "    #del learn, data, ds_train, ds_val\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b1e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learn.model.module.state_dict(),os.path.join(OUT,f'{fname}_{fold}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7121588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ce3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = 'experiments'\n",
    "fname = 'init20'\n",
    "\n",
    "for fold in range(1):\n",
    "    ds_train = ContrailsDataset(CONFIG.path, train=True)\n",
    "    ds_val = ContrailsDataset(CONFIG.path, train=False, tfms=None)\n",
    "    \n",
    "    data = ImageDataLoaders.from_dsets(ds_train,\n",
    "                                   ds_val,\n",
    "                                   bs=CONFIG.bs,\n",
    "                                   num_workers=CONFIG.num_workers,\n",
    "                                   pin_memory=True\n",
    "                                  ).cuda()\n",
    "\n",
    "    model = SegFormer(arch='B2', pre='segformer.b2.512x512.ade.160k.pth', num_classes=1, \n",
    "                      ps=0,up_result=1, tta=8).cuda()\n",
    "    model.load_state_dict(torch.load(os.path.join(OUT,f'{fname}_{fold}.pth')))\n",
    "    model = nn.DataParallel(model)\n",
    "    learn = Learner(data, \n",
    "                    model,\n",
    "                    path = CONFIG.out, \n",
    "                    loss_func=lovasz_sym,\n",
    "                    metrics=[F_th()],\n",
    "                    cbs=[\n",
    "                    GradientClip(3.0),\n",
    "                    GradientAccumulation(32//CONFIG.bs),\n",
    "                    CSVLogger(),\n",
    "                    #SaveModelCallback(monitor='f_th'),\n",
    "                    #EMAWarmupCallback(final_decay=0.998)\n",
    "                    ],\n",
    "                    opt_func=partial(WrapperOver9000,eps=1e-4),\n",
    "                   ).to_fp16()\n",
    "    \n",
    "    #learn.fit_one_cycle(24, lr_max=4e-4, pct_start=0.05)\n",
    "    #torch.save(learn.model.module.state_dict(),os.path.join(OUT,f'{fname}_{fold}.pth'))\n",
    "    \n",
    "    #del learn, data, ds_train, ds_val\n",
    "    #gc.collect()\n",
    "    #torch.cuda.empty_cache()\n",
    "    learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05cba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = learn.metrics[0]\n",
    "dices = (1 + metric.beta**2)*metric.tp/\\\n",
    "        ((1 + metric.beta**2)*metric.tp + metric.beta**2*metric.fn + metric.fp + 1e-6)\n",
    "ths = metric.ths\n",
    "\n",
    "best_dice = dices.max()\n",
    "best_thr = ths[dices.argmax()]\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(ths, dices, color='blue')\n",
    "plt.vlines(x=best_thr, ymin=dices.min(), ymax=dices.max(), colors='black')\n",
    "d = dices.max() - dices.min()\n",
    "plt.text(ths[-1]-0.1, best_dice-0.1*d, f'DICE = {best_dice:.3f}', fontsize=12);\n",
    "plt.text(ths[-1]-0.1, best_dice-0.2*d, f'TH = {best_thr:.3f}', fontsize=12);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bc6246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c1cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
